{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np \n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "df =pd.read_csv(r\"https://raw.githubusercontent.com/dphi-official/Datasets/master/Boston_Housing/Training_set_boston.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "about the data set\n",
    "We will be working on a data set that comes from the real estate industry in Boston (US). This database contains 14 attributes. The target variable refers to the median value of owner-occupied homes in 1000 USD's."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CRIM</th>\n",
       "      <th>ZN</th>\n",
       "      <th>INDUS</th>\n",
       "      <th>CHAS</th>\n",
       "      <th>NOX</th>\n",
       "      <th>RM</th>\n",
       "      <th>AGE</th>\n",
       "      <th>DIS</th>\n",
       "      <th>RAD</th>\n",
       "      <th>TAX</th>\n",
       "      <th>PTRATIO</th>\n",
       "      <th>B</th>\n",
       "      <th>LSTAT</th>\n",
       "      <th>MEDV</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>15.02340</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18.10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.6140</td>\n",
       "      <td>5.304</td>\n",
       "      <td>97.3</td>\n",
       "      <td>2.1007</td>\n",
       "      <td>24.0</td>\n",
       "      <td>666.0</td>\n",
       "      <td>20.2</td>\n",
       "      <td>349.48</td>\n",
       "      <td>24.91</td>\n",
       "      <td>12.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.62739</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.14</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5380</td>\n",
       "      <td>5.834</td>\n",
       "      <td>56.5</td>\n",
       "      <td>4.4986</td>\n",
       "      <td>4.0</td>\n",
       "      <td>307.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>395.62</td>\n",
       "      <td>8.47</td>\n",
       "      <td>19.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.03466</td>\n",
       "      <td>35.0</td>\n",
       "      <td>6.06</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.4379</td>\n",
       "      <td>6.031</td>\n",
       "      <td>23.3</td>\n",
       "      <td>6.6407</td>\n",
       "      <td>1.0</td>\n",
       "      <td>304.0</td>\n",
       "      <td>16.9</td>\n",
       "      <td>362.25</td>\n",
       "      <td>7.83</td>\n",
       "      <td>19.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7.05042</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18.10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.6140</td>\n",
       "      <td>6.103</td>\n",
       "      <td>85.1</td>\n",
       "      <td>2.0218</td>\n",
       "      <td>24.0</td>\n",
       "      <td>666.0</td>\n",
       "      <td>20.2</td>\n",
       "      <td>2.52</td>\n",
       "      <td>23.29</td>\n",
       "      <td>13.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.72580</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.14</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5380</td>\n",
       "      <td>5.727</td>\n",
       "      <td>69.5</td>\n",
       "      <td>3.7965</td>\n",
       "      <td>4.0</td>\n",
       "      <td>307.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>390.95</td>\n",
       "      <td>11.28</td>\n",
       "      <td>18.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       CRIM    ZN  INDUS  CHAS     NOX     RM   AGE     DIS   RAD    TAX  \\\n",
       "0  15.02340   0.0  18.10   0.0  0.6140  5.304  97.3  2.1007  24.0  666.0   \n",
       "1   0.62739   0.0   8.14   0.0  0.5380  5.834  56.5  4.4986   4.0  307.0   \n",
       "2   0.03466  35.0   6.06   0.0  0.4379  6.031  23.3  6.6407   1.0  304.0   \n",
       "3   7.05042   0.0  18.10   0.0  0.6140  6.103  85.1  2.0218  24.0  666.0   \n",
       "4   0.72580   0.0   8.14   0.0  0.5380  5.727  69.5  3.7965   4.0  307.0   \n",
       "\n",
       "   PTRATIO       B  LSTAT  MEDV  \n",
       "0     20.2  349.48  24.91  12.0  \n",
       "1     21.0  395.62   8.47  19.9  \n",
       "2     16.9  362.25   7.83  19.4  \n",
       "3     20.2    2.52  23.29  13.4  \n",
       "4     21.0  390.95  11.28  18.2  "
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Pre-Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(404, 14)"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['CRIM', 'ZN', 'INDUS', 'CHAS', 'NOX', 'RM', 'AGE', 'DIS', 'RAD', 'TAX',\n",
       "       'PTRATIO', 'B', 'LSTAT', 'MEDV'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CRIM       float64\n",
       "ZN         float64\n",
       "INDUS      float64\n",
       "CHAS       float64\n",
       "NOX        float64\n",
       "RM         float64\n",
       "AGE        float64\n",
       "DIS        float64\n",
       "RAD        float64\n",
       "TAX        float64\n",
       "PTRATIO    float64\n",
       "B          float64\n",
       "LSTAT      float64\n",
       "MEDV       float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes # No categorical data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 404 entries, 0 to 403\n",
      "Data columns (total 14 columns):\n",
      " #   Column   Non-Null Count  Dtype  \n",
      "---  ------   --------------  -----  \n",
      " 0   CRIM     404 non-null    float64\n",
      " 1   ZN       404 non-null    float64\n",
      " 2   INDUS    404 non-null    float64\n",
      " 3   CHAS     404 non-null    float64\n",
      " 4   NOX      404 non-null    float64\n",
      " 5   RM       404 non-null    float64\n",
      " 6   AGE      404 non-null    float64\n",
      " 7   DIS      404 non-null    float64\n",
      " 8   RAD      404 non-null    float64\n",
      " 9   TAX      404 non-null    float64\n",
      " 10  PTRATIO  404 non-null    float64\n",
      " 11  B        404 non-null    float64\n",
      " 12  LSTAT    404 non-null    float64\n",
      " 13  MEDV     404 non-null    float64\n",
      "dtypes: float64(14)\n",
      "memory usage: 44.3 KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CRIM       0\n",
       "ZN         0\n",
       "INDUS      0\n",
       "CHAS       0\n",
       "NOX        0\n",
       "RM         0\n",
       "AGE        0\n",
       "DIS        0\n",
       "RAD        0\n",
       "TAX        0\n",
       "PTRATIO    0\n",
       "B          0\n",
       "LSTAT      0\n",
       "MEDV       0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "there are no missing values and no noise in the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "207"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df.MEDV.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CRIM</th>\n",
       "      <th>ZN</th>\n",
       "      <th>INDUS</th>\n",
       "      <th>CHAS</th>\n",
       "      <th>NOX</th>\n",
       "      <th>RM</th>\n",
       "      <th>AGE</th>\n",
       "      <th>DIS</th>\n",
       "      <th>RAD</th>\n",
       "      <th>TAX</th>\n",
       "      <th>PTRATIO</th>\n",
       "      <th>B</th>\n",
       "      <th>LSTAT</th>\n",
       "      <th>MEDV</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>404.000000</td>\n",
       "      <td>404.000000</td>\n",
       "      <td>404.000000</td>\n",
       "      <td>404.000000</td>\n",
       "      <td>404.000000</td>\n",
       "      <td>404.000000</td>\n",
       "      <td>404.000000</td>\n",
       "      <td>404.000000</td>\n",
       "      <td>404.000000</td>\n",
       "      <td>404.000000</td>\n",
       "      <td>404.000000</td>\n",
       "      <td>404.000000</td>\n",
       "      <td>404.000000</td>\n",
       "      <td>404.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>3.609125</td>\n",
       "      <td>11.569307</td>\n",
       "      <td>10.985050</td>\n",
       "      <td>0.071782</td>\n",
       "      <td>0.556484</td>\n",
       "      <td>6.315891</td>\n",
       "      <td>68.556436</td>\n",
       "      <td>3.808195</td>\n",
       "      <td>9.356436</td>\n",
       "      <td>404.032178</td>\n",
       "      <td>18.318317</td>\n",
       "      <td>356.278342</td>\n",
       "      <td>12.457351</td>\n",
       "      <td>22.796535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>8.875058</td>\n",
       "      <td>23.152481</td>\n",
       "      <td>6.894618</td>\n",
       "      <td>0.258447</td>\n",
       "      <td>0.117704</td>\n",
       "      <td>0.709452</td>\n",
       "      <td>27.994922</td>\n",
       "      <td>2.131226</td>\n",
       "      <td>8.589721</td>\n",
       "      <td>166.172655</td>\n",
       "      <td>2.228701</td>\n",
       "      <td>91.566533</td>\n",
       "      <td>7.110381</td>\n",
       "      <td>9.332147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.009060</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.740000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.385000</td>\n",
       "      <td>3.863000</td>\n",
       "      <td>2.900000</td>\n",
       "      <td>1.129600</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>187.000000</td>\n",
       "      <td>12.600000</td>\n",
       "      <td>0.320000</td>\n",
       "      <td>1.730000</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.081437</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.130000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.452000</td>\n",
       "      <td>5.890500</td>\n",
       "      <td>45.550000</td>\n",
       "      <td>2.087875</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>279.000000</td>\n",
       "      <td>16.800000</td>\n",
       "      <td>375.472500</td>\n",
       "      <td>6.772500</td>\n",
       "      <td>16.950000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.261390</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>8.560000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.538000</td>\n",
       "      <td>6.210000</td>\n",
       "      <td>77.700000</td>\n",
       "      <td>3.175750</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>330.000000</td>\n",
       "      <td>18.700000</td>\n",
       "      <td>391.305000</td>\n",
       "      <td>10.925000</td>\n",
       "      <td>21.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>3.202962</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>18.100000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.631000</td>\n",
       "      <td>6.636750</td>\n",
       "      <td>93.650000</td>\n",
       "      <td>5.400800</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>666.000000</td>\n",
       "      <td>20.200000</td>\n",
       "      <td>395.755000</td>\n",
       "      <td>16.372500</td>\n",
       "      <td>26.400000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>88.976200</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>27.740000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.871000</td>\n",
       "      <td>8.780000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>12.126500</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>711.000000</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>396.900000</td>\n",
       "      <td>37.970000</td>\n",
       "      <td>50.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             CRIM          ZN       INDUS        CHAS         NOX          RM  \\\n",
       "count  404.000000  404.000000  404.000000  404.000000  404.000000  404.000000   \n",
       "mean     3.609125   11.569307   10.985050    0.071782    0.556484    6.315891   \n",
       "std      8.875058   23.152481    6.894618    0.258447    0.117704    0.709452   \n",
       "min      0.009060    0.000000    0.740000    0.000000    0.385000    3.863000   \n",
       "25%      0.081437    0.000000    5.130000    0.000000    0.452000    5.890500   \n",
       "50%      0.261390    0.000000    8.560000    0.000000    0.538000    6.210000   \n",
       "75%      3.202962   20.000000   18.100000    0.000000    0.631000    6.636750   \n",
       "max     88.976200  100.000000   27.740000    1.000000    0.871000    8.780000   \n",
       "\n",
       "              AGE         DIS         RAD         TAX     PTRATIO           B  \\\n",
       "count  404.000000  404.000000  404.000000  404.000000  404.000000  404.000000   \n",
       "mean    68.556436    3.808195    9.356436  404.032178   18.318317  356.278342   \n",
       "std     27.994922    2.131226    8.589721  166.172655    2.228701   91.566533   \n",
       "min      2.900000    1.129600    1.000000  187.000000   12.600000    0.320000   \n",
       "25%     45.550000    2.087875    4.000000  279.000000   16.800000  375.472500   \n",
       "50%     77.700000    3.175750    5.000000  330.000000   18.700000  391.305000   \n",
       "75%     93.650000    5.400800   12.000000  666.000000   20.200000  395.755000   \n",
       "max    100.000000   12.126500   24.000000  711.000000   22.000000  396.900000   \n",
       "\n",
       "            LSTAT        MEDV  \n",
       "count  404.000000  404.000000  \n",
       "mean    12.457351   22.796535  \n",
       "std      7.110381    9.332147  \n",
       "min      1.730000    5.000000  \n",
       "25%      6.772500   16.950000  \n",
       "50%     10.925000   21.600000  \n",
       "75%     16.372500   26.400000  \n",
       "max     37.970000   50.000000  "
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.barplot(data=df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.boxplot(data=df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[402.,   2.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.],\n",
       "        [380.,  24.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.],\n",
       "        [404.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.],\n",
       "        [404.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.],\n",
       "        [404.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.],\n",
       "        [404.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.],\n",
       "        [179., 225.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.],\n",
       "        [404.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.],\n",
       "        [404.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.],\n",
       "        [  0.,   0.,  16.,  97., 104.,  59.,  24.,   0.,   0., 104.],\n",
       "        [404.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.],\n",
       "        [ 19.,  10.,   4.,   6.,  36., 329.,   0.,   0.,   0.,   0.],\n",
       "        [404.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.],\n",
       "        [404.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.]]),\n",
       " array([  0. ,  71.1, 142.2, 213.3, 284.4, 355.5, 426.6, 497.7, 568.8,\n",
       "        639.9, 711. ]),\n",
       " <a list of 14 BarContainer objects>)"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 18.,  43.,  63., 121.,  66.,  33.,  26.,   8.,   9.,  17.]),\n",
       " array([ 5. ,  9.5, 14. , 18.5, 23. , 27.5, 32. , 36.5, 41. , 45.5, 50. ]),\n",
       " <BarContainer object of 10 artists>)"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(df['MEDV'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=df.iloc[:,0:-1]\n",
    "y=df['MEDV']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,y_train,y_test =train_test_split(X,y,test_size =0.3,random_state =42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((282, 13), (282,), (122, 13), (122,))"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape,y_train.shape,X_test.shape,y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13\n"
     ]
    }
   ],
   "source": [
    "n_features =X.shape[1]\n",
    "print(n_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the 5 step model life Cycle\n",
    "1.Define the model\n",
    "2.Compile the model\n",
    "3.fit the model\n",
    "4.Make predictions on the model\n",
    "5.Evaluate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import statements\n",
    "from tensorflow.keras import Sequential#import Sequential  from tensorflow.keras\n",
    "from tensorflow.keras.layers import Dense# import dense form tensorflow.keras.layers\n",
    "from numpy.random import seed #  this seed helps us to fix the randomness in the neural network\n",
    "import tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Defining the model\n",
    "model=Sequential()\n",
    "model.add(Dense(10,activation ='relu',input_shape =(n_features,)))\n",
    "model.add(Dense(8,activation ='relu'))\n",
    "model.add(Dense(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Compile the Model\n",
    "from tensorflow.keras.optimizers import RMSprop#importing the RMS group optimizers\n",
    "optimizer =RMSprop(0.01)#0.01 is a learning Rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we cannot analytically calculate the optimal learning rate \n",
    "# for a given model on a given dataset inseted of good learning rate must be discovered via trail and error\n",
    "#A defualt learning rate value  is 0.1 or 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=\"mean_squared_error\",optimizer =optimizer)# compile the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fitting the Model\n",
    "seed_value =42;\n",
    "seed(seed_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "#verbose 1 ==>[==============================]\n",
    "#verbose 2==> -\n",
    "#verbose 0 ==>  silent does nothing\n",
    "#verbose is nothing but we are seeing the training process for each epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 310.1216\n",
      "Epoch 2/10\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 95.6248\n",
      "Epoch 3/10\n",
      "10/10 [==============================] - 0s 887us/step - loss: 83.9177\n",
      "Epoch 4/10\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 86.3169\n",
      "Epoch 5/10\n",
      "10/10 [==============================] - 0s 958us/step - loss: 92.3867\n",
      "Epoch 6/10\n",
      "10/10 [==============================] - 0s 984us/step - loss: 86.5492\n",
      "Epoch 7/10\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 72.8030\n",
      "Epoch 8/10\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 81.5768\n",
      "Epoch 9/10\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 62.8403\n",
      "Epoch 10/10\n",
      "10/10 [==============================] - 0s 869us/step - loss: 76.2880\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x23e876a9580>"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#import numpy as np\n",
    "import random\n",
    "random.seed(seed_value)\n",
    "tensorflow.random.set_seed(seed_value)\n",
    "model.fit(X_train,y_train,epochs =10,batch_size =30,verbose =1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x23e879e0e50>"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#import numpy as np\n",
    "import random\n",
    "random.seed(seed_value)\n",
    "tensorflow.random.set_seed(seed_value)\n",
    "model.fit(X_train,y_train,epochs =10,batch_size =30,verbose =0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "10/10 - 0s - loss: 61.3444\n",
      "Epoch 2/10\n",
      "10/10 - 0s - loss: 55.3956\n",
      "Epoch 3/10\n",
      "10/10 - 0s - loss: 55.2406\n",
      "Epoch 4/10\n",
      "10/10 - 0s - loss: 59.6570\n",
      "Epoch 5/10\n",
      "10/10 - 0s - loss: 65.7754\n",
      "Epoch 6/10\n",
      "10/10 - 0s - loss: 47.2178\n",
      "Epoch 7/10\n",
      "10/10 - 0s - loss: 55.3440\n",
      "Epoch 8/10\n",
      "10/10 - 0s - loss: 46.5954\n",
      "Epoch 9/10\n",
      "10/10 - 0s - loss: 45.5358\n",
      "Epoch 10/10\n",
      "10/10 - 0s - loss: 60.1817\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x23e87a25640>"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#import numpy as np\n",
    "import random\n",
    "random.seed(seed_value)\n",
    "tensorflow.random.set_seed(seed_value)\n",
    "model.fit(X_train,y_train,epochs =10,batch_size =30,verbose =2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 2ms/step - loss: 36.6996\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "36.699642181396484"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred =model.predict(X_test)#predictions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "let me play with learning Rate..?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "10/10 - 0s - loss: 654863296.0000\n",
      "Epoch 2/25\n",
      "10/10 - 0s - loss: 113861.7031\n",
      "Epoch 3/25\n",
      "10/10 - 0s - loss: 5286072.0000\n",
      "Epoch 4/25\n",
      "10/10 - 0s - loss: 3133102.2500\n",
      "Epoch 5/25\n",
      "10/10 - 0s - loss: 1570757.1250\n",
      "Epoch 6/25\n",
      "10/10 - 0s - loss: 1369673.3750\n",
      "Epoch 7/25\n",
      "10/10 - 0s - loss: 1400582.5000\n",
      "Epoch 8/25\n",
      "10/10 - 0s - loss: 2655.6677\n",
      "Epoch 9/25\n",
      "10/10 - 0s - loss: 14893.5869\n",
      "Epoch 10/25\n",
      "10/10 - 0s - loss: 432976.9375\n",
      "Epoch 11/25\n",
      "10/10 - 0s - loss: 585.2492\n",
      "Epoch 12/25\n",
      "10/10 - 0s - loss: 223.4039\n",
      "Epoch 13/25\n",
      "10/10 - 0s - loss: 173.5621\n",
      "Epoch 14/25\n",
      "10/10 - 0s - loss: 126.9431\n",
      "Epoch 15/25\n",
      "10/10 - 0s - loss: 206.9944\n",
      "Epoch 16/25\n",
      "10/10 - 0s - loss: 902.6724\n",
      "Epoch 17/25\n",
      "10/10 - 0s - loss: 69.5802\n",
      "Epoch 18/25\n",
      "10/10 - 0s - loss: 88.4912\n",
      "Epoch 19/25\n",
      "10/10 - 0s - loss: 148.6532\n",
      "Epoch 20/25\n",
      "10/10 - 0s - loss: 215.2000\n",
      "Epoch 21/25\n",
      "10/10 - 0s - loss: 102.7866\n",
      "Epoch 22/25\n",
      "10/10 - 0s - loss: 136.6274\n",
      "Epoch 23/25\n",
      "10/10 - 0s - loss: 99.7908\n",
      "Epoch 24/25\n",
      "10/10 - 0s - loss: 107.9420\n",
      "Epoch 25/25\n",
      "10/10 - 0s - loss: 95.3888\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x23e87b07700>"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learning_rate =0.5\n",
    "optimizer =RMSprop(learning_rate)\n",
    "epoch=25;\n",
    "verbosee=2\n",
    "model.compile(loss =\"mean_squared_error\",optimizer=optimizer)\n",
    "model.fit(X_train,y_train,epochs =epoch,batch_size =30,verbose =verbosee)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/55\n",
      "10/10 - 1s - loss: 114.4242\n",
      "Epoch 2/55\n",
      "10/10 - 0s - loss: 92.1839\n",
      "Epoch 3/55\n",
      "10/10 - 0s - loss: 100.5270\n",
      "Epoch 4/55\n",
      "10/10 - 0s - loss: 95.7648\n",
      "Epoch 5/55\n",
      "10/10 - 0s - loss: 97.3629\n",
      "Epoch 6/55\n",
      "10/10 - 0s - loss: 99.7431\n",
      "Epoch 7/55\n",
      "10/10 - 0s - loss: 104.9269\n",
      "Epoch 8/55\n",
      "10/10 - 0s - loss: 93.7444\n",
      "Epoch 9/55\n",
      "10/10 - 0s - loss: 97.6276\n",
      "Epoch 10/55\n",
      "10/10 - 0s - loss: 93.0593\n",
      "Epoch 11/55\n",
      "10/10 - 0s - loss: 100.8283\n",
      "Epoch 12/55\n",
      "10/10 - 0s - loss: 97.3362\n",
      "Epoch 13/55\n",
      "10/10 - 0s - loss: 93.3961\n",
      "Epoch 14/55\n",
      "10/10 - 0s - loss: 98.8399\n",
      "Epoch 15/55\n",
      "10/10 - 0s - loss: 96.6525\n",
      "Epoch 16/55\n",
      "10/10 - 0s - loss: 99.0798\n",
      "Epoch 17/55\n",
      "10/10 - 0s - loss: 94.7616\n",
      "Epoch 18/55\n",
      "10/10 - 0s - loss: 95.9240\n",
      "Epoch 19/55\n",
      "10/10 - 0s - loss: 97.0025\n",
      "Epoch 20/55\n",
      "10/10 - 0s - loss: 97.8438\n",
      "Epoch 21/55\n",
      "10/10 - 0s - loss: 97.7455\n",
      "Epoch 22/55\n",
      "10/10 - 0s - loss: 112.0269\n",
      "Epoch 23/55\n",
      "10/10 - 0s - loss: 96.7607\n",
      "Epoch 24/55\n",
      "10/10 - 0s - loss: 100.1744\n",
      "Epoch 25/55\n",
      "10/10 - 0s - loss: 94.4080\n",
      "Epoch 26/55\n",
      "10/10 - 0s - loss: 109.3669\n",
      "Epoch 27/55\n",
      "10/10 - 0s - loss: 101.8844\n",
      "Epoch 28/55\n",
      "10/10 - 0s - loss: 91.2789\n",
      "Epoch 29/55\n",
      "10/10 - 0s - loss: 105.6220\n",
      "Epoch 30/55\n",
      "10/10 - 0s - loss: 91.2998\n",
      "Epoch 31/55\n",
      "10/10 - 0s - loss: 107.6424\n",
      "Epoch 32/55\n",
      "10/10 - 0s - loss: 91.5528\n",
      "Epoch 33/55\n",
      "10/10 - 0s - loss: 101.9718\n",
      "Epoch 34/55\n",
      "10/10 - 0s - loss: 100.8687\n",
      "Epoch 35/55\n",
      "10/10 - 0s - loss: 99.5391\n",
      "Epoch 36/55\n",
      "10/10 - 0s - loss: 95.9239\n",
      "Epoch 37/55\n",
      "10/10 - 0s - loss: 94.0567\n",
      "Epoch 38/55\n",
      "10/10 - 0s - loss: 107.7587\n",
      "Epoch 39/55\n",
      "10/10 - 0s - loss: 95.3253\n",
      "Epoch 40/55\n",
      "10/10 - 0s - loss: 98.1626\n",
      "Epoch 41/55\n",
      "10/10 - 0s - loss: 95.6172\n",
      "Epoch 42/55\n",
      "10/10 - 0s - loss: 97.5415\n",
      "Epoch 43/55\n",
      "10/10 - 0s - loss: 101.4301\n",
      "Epoch 44/55\n",
      "10/10 - 0s - loss: 106.9037\n",
      "Epoch 45/55\n",
      "10/10 - 0s - loss: 94.2416\n",
      "Epoch 46/55\n",
      "10/10 - 0s - loss: 102.4278\n",
      "Epoch 47/55\n",
      "10/10 - 0s - loss: 91.5884\n",
      "Epoch 48/55\n",
      "10/10 - 0s - loss: 97.7499\n",
      "Epoch 49/55\n",
      "10/10 - 0s - loss: 101.8892\n",
      "Epoch 50/55\n",
      "10/10 - 0s - loss: 92.5185\n",
      "Epoch 51/55\n",
      "10/10 - 0s - loss: 106.2836\n",
      "Epoch 52/55\n",
      "10/10 - 0s - loss: 100.4134\n",
      "Epoch 53/55\n",
      "10/10 - 0s - loss: 95.3947\n",
      "Epoch 54/55\n",
      "10/10 - 0s - loss: 97.4964\n",
      "Epoch 55/55\n",
      "10/10 - 0s - loss: 97.7363\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x23e89182f70>"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learning_rate =5.0\n",
    "optimizer =RMSprop(learning_rate)\n",
    "epoch=55;\n",
    "verbosee=2\n",
    "model.compile(loss =\"mean_squared_error\",optimizer=optimizer)\n",
    "model.fit(X_train,y_train,epochs =epoch,batch_size =30,verbose =verbosee)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 49136.2422\n",
      "Epoch 2/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 275.4187\n",
      "Epoch 3/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 114.0035\n",
      "Epoch 4/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 114.8271\n",
      "Epoch 5/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 102.4311\n",
      "Epoch 6/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 193.0973\n",
      "Epoch 7/100\n",
      "10/10 [==============================] - 0s 985us/step - loss: 196.8468\n",
      "Epoch 8/100\n",
      "10/10 [==============================] - 0s 953us/step - loss: 215.6512\n",
      "Epoch 9/100\n",
      "10/10 [==============================] - 0s 995us/step - loss: 296.4408\n",
      "Epoch 10/100\n",
      "10/10 [==============================] - 0s 872us/step - loss: 428.0375\n",
      "Epoch 11/100\n",
      "10/10 [==============================] - 0s 866us/step - loss: 304.0753\n",
      "Epoch 12/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 163.5363\n",
      "Epoch 13/100\n",
      "10/10 [==============================] - 0s 892us/step - loss: 97.7797\n",
      "Epoch 14/100\n",
      "10/10 [==============================] - 0s 832us/step - loss: 91.1177\n",
      "Epoch 15/100\n",
      "10/10 [==============================] - 0s 964us/step - loss: 90.9501\n",
      "Epoch 16/100\n",
      "10/10 [==============================] - 0s 997us/step - loss: 91.0210\n",
      "Epoch 17/100\n",
      "10/10 [==============================] - 0s 829us/step - loss: 90.6991\n",
      "Epoch 18/100\n",
      "10/10 [==============================] - 0s 948us/step - loss: 90.9784\n",
      "Epoch 19/100\n",
      "10/10 [==============================] - 0s 828us/step - loss: 92.9751\n",
      "Epoch 20/100\n",
      "10/10 [==============================] - 0s 883us/step - loss: 92.3787\n",
      "Epoch 21/100\n",
      "10/10 [==============================] - 0s 978us/step - loss: 92.1408\n",
      "Epoch 22/100\n",
      "10/10 [==============================] - 0s 886us/step - loss: 95.5256\n",
      "Epoch 23/100\n",
      "10/10 [==============================] - 0s 885us/step - loss: 92.6387\n",
      "Epoch 24/100\n",
      "10/10 [==============================] - 0s 996us/step - loss: 93.2018\n",
      "Epoch 25/100\n",
      "10/10 [==============================] - 0s 887us/step - loss: 90.9758\n",
      "Epoch 26/100\n",
      "10/10 [==============================] - 0s 903us/step - loss: 93.5925\n",
      "Epoch 27/100\n",
      "10/10 [==============================] - 0s 885us/step - loss: 93.7102\n",
      "Epoch 28/100\n",
      "10/10 [==============================] - 0s 886us/step - loss: 90.6094\n",
      "Epoch 29/100\n",
      "10/10 [==============================] - 0s 886us/step - loss: 93.1463\n",
      "Epoch 30/100\n",
      "10/10 [==============================] - 0s 997us/step - loss: 90.7801\n",
      "Epoch 31/100\n",
      "10/10 [==============================] - 0s 953us/step - loss: 93.9842\n",
      "Epoch 32/100\n",
      "10/10 [==============================] - 0s 999us/step - loss: 90.7841\n",
      "Epoch 33/100\n",
      "10/10 [==============================] - 0s 910us/step - loss: 91.9514\n",
      "Epoch 34/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 92.2153\n",
      "Epoch 35/100\n",
      "10/10 [==============================] - 0s 886us/step - loss: 92.7691\n",
      "Epoch 36/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 91.3929\n",
      "Epoch 37/100\n",
      "10/10 [==============================] - 0s 998us/step - loss: 91.6565\n",
      "Epoch 38/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 93.4642\n",
      "Epoch 39/100\n",
      "10/10 [==============================] - 0s 997us/step - loss: 91.2202\n",
      "Epoch 40/100\n",
      "10/10 [==============================] - 0s 997us/step - loss: 91.6249\n",
      "Epoch 41/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 91.7061\n",
      "Epoch 42/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 92.9047\n",
      "Epoch 43/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 92.6321\n",
      "Epoch 44/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 93.2989\n",
      "Epoch 45/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 91.2912\n",
      "Epoch 46/100\n",
      "10/10 [==============================] - 0s 898us/step - loss: 92.3553\n",
      "Epoch 47/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 90.3315\n",
      "Epoch 48/100\n",
      "10/10 [==============================] - 0s 886us/step - loss: 92.3693\n",
      "Epoch 49/100\n",
      "10/10 [==============================] - 0s 933us/step - loss: 92.2307\n",
      "Epoch 50/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 90.5833\n",
      "Epoch 51/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 94.0032\n",
      "Epoch 52/100\n",
      "10/10 [==============================] - 0s 886us/step - loss: 91.8925\n",
      "Epoch 53/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 90.2553\n",
      "Epoch 54/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 91.9352\n",
      "Epoch 55/100\n",
      "10/10 [==============================] - 0s 941us/step - loss: 90.9281\n",
      "Epoch 56/100\n",
      "10/10 [==============================] - 0s 940us/step - loss: 91.5688\n",
      "Epoch 57/100\n",
      "10/10 [==============================] - 0s 895us/step - loss: 94.1637\n",
      "Epoch 58/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 92.5102\n",
      "Epoch 59/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 93.2700\n",
      "Epoch 60/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 94.7147\n",
      "Epoch 61/100\n",
      "10/10 [==============================] - 0s 775us/step - loss: 92.6309\n",
      "Epoch 62/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 91.1385\n",
      "Epoch 63/100\n",
      "10/10 [==============================] - 0s 973us/step - loss: 92.5291\n",
      "Epoch 64/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 91.0462\n",
      "Epoch 65/100\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 93.9582\n",
      "Epoch 66/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 91.0534\n",
      "Epoch 67/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 91.3344\n",
      "Epoch 68/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 91.5595\n",
      "Epoch 69/100\n",
      "10/10 [==============================] - 0s 996us/step - loss: 94.1208\n",
      "Epoch 70/100\n",
      "10/10 [==============================] - 0s 895us/step - loss: 91.0971\n",
      "Epoch 71/100\n",
      "10/10 [==============================] - 0s 885us/step - loss: 91.9611\n",
      "Epoch 72/100\n",
      "10/10 [==============================] - 0s 876us/step - loss: 91.8264\n",
      "Epoch 73/100\n",
      "10/10 [==============================] - 0s 954us/step - loss: 92.9920\n",
      "Epoch 74/100\n",
      "10/10 [==============================] - 0s 943us/step - loss: 95.1098\n",
      "Epoch 75/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 90.2537\n",
      "Epoch 76/100\n",
      "10/10 [==============================] - 0s 997us/step - loss: 92.3072\n",
      "Epoch 77/100\n",
      "10/10 [==============================] - 0s 946us/step - loss: 91.7315\n",
      "Epoch 78/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 93.5376\n",
      "Epoch 79/100\n",
      "10/10 [==============================] - 0s 970us/step - loss: 91.2140\n",
      "Epoch 80/100\n",
      "10/10 [==============================] - 0s 885us/step - loss: 90.8689\n",
      "Epoch 81/100\n",
      "10/10 [==============================] - 0s 943us/step - loss: 91.3955\n",
      "Epoch 82/100\n",
      "10/10 [==============================] - ETA: 0s - loss: 35.07 - 0s 1ms/step - loss: 89.7051\n",
      "Epoch 83/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 91.9365\n",
      "Epoch 84/100\n",
      "10/10 [==============================] - 0s 997us/step - loss: 91.4655\n",
      "Epoch 85/100\n",
      "10/10 [==============================] - 0s 783us/step - loss: 94.2006\n",
      "Epoch 86/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 91.8277\n",
      "Epoch 87/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 91.0885\n",
      "Epoch 88/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 91.8150\n",
      "Epoch 89/100\n",
      "10/10 [==============================] - 0s 997us/step - loss: 93.7463\n",
      "Epoch 90/100\n",
      "10/10 [==============================] - 0s 917us/step - loss: 91.5460\n",
      "Epoch 91/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 93.0930\n",
      "Epoch 92/100\n",
      "10/10 [==============================] - 0s 888us/step - loss: 91.7808\n",
      "Epoch 93/100\n",
      "10/10 [==============================] - 0s 797us/step - loss: 92.4528\n",
      "Epoch 94/100\n",
      "10/10 [==============================] - 0s 886us/step - loss: 91.0097\n",
      "Epoch 95/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 94.7356\n",
      "Epoch 96/100\n",
      "10/10 [==============================] - 0s 791us/step - loss: 90.7531\n",
      "Epoch 97/100\n",
      "10/10 [==============================] - 0s 997us/step - loss: 91.6151\n",
      "Epoch 98/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 91.0125\n",
      "Epoch 99/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 0s 886us/step - loss: 94.5881\n",
      "Epoch 100/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 91.5862\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 83.4685\n",
      "The MSE value is:  83.4684829711914\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(10, activation='relu', input_shape=(n_features,)))\n",
    "model.add(Dense(8, activation='relu'))\n",
    "model.add(Dense(1))\n",
    "\n",
    "optimizer = RMSprop(0.1) # 0.1 is the learning rate\n",
    "model.compile(loss='mean_squared_error',optimizer=optimizer) # compile the model\n",
    "\n",
    "# fit the model\n",
    "model.fit(X_train, y_train, epochs=100, batch_size=30, verbose = 1)\n",
    "\n",
    "# evaluate the model\n",
    "print('The MSE value is: ', model.evaluate(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/111\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 116.5390\n",
      "Epoch 2/111\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 92.1575\n",
      "Epoch 3/111\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 100.2203\n",
      "Epoch 4/111\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 95.7935\n",
      "Epoch 5/111\n",
      "10/10 [==============================] - 0s 996us/step - loss: 97.3634\n",
      "Epoch 6/111\n",
      "10/10 [==============================] - 0s 933us/step - loss: 99.7433\n",
      "Epoch 7/111\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 104.9268\n",
      "Epoch 8/111\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 93.7444\n",
      "Epoch 9/111\n",
      "10/10 [==============================] - 0s 752us/step - loss: 97.6276\n",
      "Epoch 10/111\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 93.0593\n",
      "Epoch 11/111\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 100.8283\n",
      "Epoch 12/111\n",
      "10/10 [==============================] - 0s 778us/step - loss: 97.3362\n",
      "Epoch 13/111\n",
      "10/10 [==============================] - 0s 885us/step - loss: 93.3961\n",
      "Epoch 14/111\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 98.8399\n",
      "Epoch 15/111\n",
      "10/10 [==============================] - 0s 879us/step - loss: 96.6525\n",
      "Epoch 16/111\n",
      "10/10 [==============================] - 0s 891us/step - loss: 99.0798\n",
      "Epoch 17/111\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 94.7616\n",
      "Epoch 18/111\n",
      "10/10 [==============================] - 0s 904us/step - loss: 95.9240\n",
      "Epoch 19/111\n",
      "10/10 [==============================] - 0s 849us/step - loss: 97.0025\n",
      "Epoch 20/111\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 97.8438\n",
      "Epoch 21/111\n",
      "10/10 [==============================] - 0s 887us/step - loss: 97.7455\n",
      "Epoch 22/111\n",
      "10/10 [==============================] - 0s 886us/step - loss: 112.0269\n",
      "Epoch 23/111\n",
      "10/10 [==============================] - 0s 997us/step - loss: 96.7607\n",
      "Epoch 24/111\n",
      "10/10 [==============================] - 0s 900us/step - loss: 100.1744\n",
      "Epoch 25/111\n",
      "10/10 [==============================] - 0s 777us/step - loss: 94.4080\n",
      "Epoch 26/111\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 109.3669\n",
      "Epoch 27/111\n",
      "10/10 [==============================] - 0s 997us/step - loss: 101.8844\n",
      "Epoch 28/111\n",
      "10/10 [==============================] - 0s 887us/step - loss: 91.2789\n",
      "Epoch 29/111\n",
      "10/10 [==============================] - 0s 934us/step - loss: 105.6220\n",
      "Epoch 30/111\n",
      "10/10 [==============================] - 0s 997us/step - loss: 91.2998\n",
      "Epoch 31/111\n",
      "10/10 [==============================] - 0s 665us/step - loss: 107.6424\n",
      "Epoch 32/111\n",
      "10/10 [==============================] - 0s 931us/step - loss: 91.5528\n",
      "Epoch 33/111\n",
      "10/10 [==============================] - 0s 887us/step - loss: 101.9718\n",
      "Epoch 34/111\n",
      "10/10 [==============================] - 0s 776us/step - loss: 100.8687\n",
      "Epoch 35/111\n",
      "10/10 [==============================] - 0s 882us/step - loss: 99.5391\n",
      "Epoch 36/111\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 95.9239\n",
      "Epoch 37/111\n",
      "10/10 [==============================] - 0s 999us/step - loss: 94.0567\n",
      "Epoch 38/111\n",
      "10/10 [==============================] - 0s 816us/step - loss: 107.7587\n",
      "Epoch 39/111\n",
      "10/10 [==============================] - 0s 952us/step - loss: 95.3253\n",
      "Epoch 40/111\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 98.1626\n",
      "Epoch 41/111\n",
      "10/10 [==============================] - 0s 780us/step - loss: 95.6172\n",
      "Epoch 42/111\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 97.5415\n",
      "Epoch 43/111\n",
      "10/10 [==============================] - 0s 997us/step - loss: 101.4301\n",
      "Epoch 44/111\n",
      "10/10 [==============================] - 0s 785us/step - loss: 106.9037\n",
      "Epoch 45/111\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 94.2416\n",
      "Epoch 46/111\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 102.4278\n",
      "Epoch 47/111\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 91.5884\n",
      "Epoch 48/111\n",
      "10/10 [==============================] - 0s 910us/step - loss: 97.7499\n",
      "Epoch 49/111\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 101.8892\n",
      "Epoch 50/111\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 92.5185\n",
      "Epoch 51/111\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 106.2836\n",
      "Epoch 52/111\n",
      "10/10 [==============================] - 0s 919us/step - loss: 100.4134\n",
      "Epoch 53/111\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 95.3947\n",
      "Epoch 54/111\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 97.4964\n",
      "Epoch 55/111\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 97.7363\n",
      "Epoch 56/111\n",
      "10/10 [==============================] - 0s 882us/step - loss: 93.5469\n",
      "Epoch 57/111\n",
      "10/10 [==============================] - 0s 940us/step - loss: 108.3560\n",
      "Epoch 58/111\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 98.4387\n",
      "Epoch 59/111\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 100.6509\n",
      "Epoch 60/111\n",
      "10/10 [==============================] - 0s 775us/step - loss: 109.0441\n",
      "Epoch 61/111\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 98.0440\n",
      "Epoch 62/111\n",
      "10/10 [==============================] - 0s 950us/step - loss: 95.5381\n",
      "Epoch 63/111\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 102.4964\n",
      "Epoch 64/111\n",
      "10/10 [==============================] - 0s 778us/step - loss: 95.4807\n",
      "Epoch 65/111\n",
      "10/10 [==============================] - 0s 886us/step - loss: 103.3591\n",
      "Epoch 66/111\n",
      "10/10 [==============================] - 0s 925us/step - loss: 94.8683\n",
      "Epoch 67/111\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 95.8245\n",
      "Epoch 68/111\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 101.1972\n",
      "Epoch 69/111\n",
      "10/10 [==============================] - 0s 945us/step - loss: 106.2921\n",
      "Epoch 70/111\n",
      "10/10 [==============================] - 0s 886us/step - loss: 90.5596\n",
      "Epoch 71/111\n",
      "10/10 [==============================] - 0s 915us/step - loss: 94.5179\n",
      "Epoch 72/111\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 100.0648\n",
      "Epoch 73/111\n",
      "10/10 [==============================] - 0s 997us/step - loss: 100.1570\n",
      "Epoch 74/111\n",
      "10/10 [==============================] - 0s 707us/step - loss: 108.1884\n",
      "Epoch 75/111\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 89.8009\n",
      "Epoch 76/111\n",
      "10/10 [==============================] - 0s 996us/step - loss: 96.3462\n",
      "Epoch 77/111\n",
      "10/10 [==============================] - 0s 777us/step - loss: 98.3909\n",
      "Epoch 78/111\n",
      "10/10 [==============================] - 0s 996us/step - loss: 103.6330\n",
      "Epoch 79/111\n",
      "10/10 [==============================] - 0s 971us/step - loss: 94.8742\n",
      "Epoch 80/111\n",
      "10/10 [==============================] - 0s 775us/step - loss: 95.4837\n",
      "Epoch 81/111\n",
      "10/10 [==============================] - 0s 936us/step - loss: 104.0358\n",
      "Epoch 82/111\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 92.3523\n",
      "Epoch 83/111\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 97.1894\n",
      "Epoch 84/111\n",
      "10/10 [==============================] - 0s 932us/step - loss: 96.2563\n",
      "Epoch 85/111\n",
      "10/10 [==============================] - ETA: 0s - loss: 61.22 - 0s 1ms/step - loss: 102.3887\n",
      "Epoch 86/111\n",
      "10/10 [==============================] - 0s 993us/step - loss: 97.5555\n",
      "Epoch 87/111\n",
      "10/10 [==============================] - 0s 775us/step - loss: 92.3126\n",
      "Epoch 88/111\n",
      "10/10 [==============================] - 0s 967us/step - loss: 102.7509\n",
      "Epoch 89/111\n",
      "10/10 [==============================] - 0s 932us/step - loss: 99.2107\n",
      "Epoch 90/111\n",
      "10/10 [==============================] - 0s 998us/step - loss: 97.9494\n",
      "Epoch 91/111\n",
      "10/10 [==============================] - 0s 962us/step - loss: 106.3492\n",
      "Epoch 92/111\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 95.0864\n",
      "Epoch 93/111\n",
      "10/10 [==============================] - 0s 883us/step - loss: 96.2282\n",
      "Epoch 94/111\n",
      "10/10 [==============================] - 0s 774us/step - loss: 97.7009\n",
      "Epoch 95/111\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 108.5546\n",
      "Epoch 96/111\n",
      "10/10 [==============================] - 0s 996us/step - loss: 91.1311\n",
      "Epoch 97/111\n",
      "10/10 [==============================] - 0s 767us/step - loss: 94.2034\n",
      "Epoch 98/111\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 0s 1ms/step - loss: 96.7011\n",
      "Epoch 99/111\n",
      "10/10 [==============================] - 0s 971us/step - loss: 113.6091\n",
      "Epoch 100/111\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 96.2606\n",
      "Epoch 101/111\n",
      "10/10 [==============================] - 0s 775us/step - loss: 105.0563\n",
      "Epoch 102/111\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 98.2578\n",
      "Epoch 103/111\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 103.4015\n",
      "Epoch 104/111\n",
      "10/10 [==============================] - 0s 775us/step - loss: 99.0202\n",
      "Epoch 105/111\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 102.6496\n",
      "Epoch 106/111\n",
      "10/10 [==============================] - 0s 885us/step - loss: 100.6995\n",
      "Epoch 107/111\n",
      "10/10 [==============================] - 0s 777us/step - loss: 93.9076\n",
      "Epoch 108/111\n",
      "10/10 [==============================] - 0s 997us/step - loss: 102.8028\n",
      "Epoch 109/111\n",
      "10/10 [==============================] - 0s 775us/step - loss: 105.8486\n",
      "Epoch 110/111\n",
      "10/10 [==============================] - 0s 776us/step - loss: 95.2447\n",
      "Epoch 111/111\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 103.1028\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x23e8be40730>"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learning_rate =5.0\n",
    "optimizer =RMSprop(learning_rate)\n",
    "epoch=111;\n",
    "verbosee=1\n",
    "model.compile(loss =\"mean_squared_error\",optimizer=optimizer)\n",
    "model.fit(X_train,y_train,epochs =epoch,batch_size =30,verbose =verbosee)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "8/8 [==============================] - 1s 2ms/step - loss: 41304.3750\n",
      "Epoch 2/10\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 1490.7942\n",
      "Epoch 3/10\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 511.0619\n",
      "Epoch 4/10\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 129.2097\n",
      "Epoch 5/10\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 109.7583\n",
      "Epoch 6/10\n",
      "8/8 [==============================] - 0s 919us/step - loss: 107.3668\n",
      "Epoch 7/10\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 116.8011\n",
      "Epoch 8/10\n",
      "8/8 [==============================] - 0s 907us/step - loss: 105.1240\n",
      "Epoch 9/10\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 228.1693\n",
      "Epoch 10/10\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 97.8506\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 187.3347\n",
      "The MSE value is:  187.334716796875\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(10, activation='relu', input_shape=(n_features,)))\n",
    "model.add(Dense(8, activation='relu'))\n",
    "model.add(Dense(1))\n",
    "\n",
    "optimizer = RMSprop(0.1) # 0.1 is the learning rate\n",
    "model.compile(loss='mean_squared_error',optimizer=optimizer) # compile the model\n",
    "\n",
    "# fit the model\n",
    "model.fit(X_train, y_train, epochs=10, batch_size=40, verbose = 1)\n",
    "\n",
    "# evaluate the model\n",
    "print('The MSE value is: ', model.evaluate(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "15/15 [==============================] - 1s 2ms/step - loss: 33289.9102\n",
      "Epoch 2/10\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 249.6192\n",
      "Epoch 3/10\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 85.1666\n",
      "Epoch 4/10\n",
      "15/15 [==============================] - 0s 933us/step - loss: 116.5944\n",
      "Epoch 5/10\n",
      "15/15 [==============================] - 0s 897us/step - loss: 147.6005\n",
      "Epoch 6/10\n",
      "15/15 [==============================] - 0s 784us/step - loss: 414.3831\n",
      "Epoch 7/10\n",
      "15/15 [==============================] - 0s 814us/step - loss: 203.2904\n",
      "Epoch 8/10\n",
      "15/15 [==============================] - 0s 783us/step - loss: 154.3219\n",
      "Epoch 9/10\n",
      "15/15 [==============================] - 0s 829us/step - loss: 126.7281\n",
      "Epoch 10/10\n",
      "15/15 [==============================] - 0s 915us/step - loss: 220.8293\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 1241.9556\n",
      "The MSE value is:  1241.95556640625\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(10, activation='relu', input_shape=(n_features,)))\n",
    "model.add(Dense(8, activation='relu'))\n",
    "model.add(Dense(1))\n",
    "\n",
    "optimizer = RMSprop(0.1) # 0.1 is the learning rate\n",
    "model.compile(loss='mean_squared_error',optimizer=optimizer) # compile the model\n",
    "\n",
    "# fit the model\n",
    "model.fit(X_train, y_train, epochs=10, batch_size=20, verbose = 1)\n",
    "\n",
    "# evaluate the model\n",
    "print('The MSE value is: ', model.evaluate(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "19/19 [==============================] - 0s 1ms/step - loss: 54003.8789\n",
      "Epoch 2/10\n",
      "19/19 [==============================] - 0s 976us/step - loss: 1109.3523\n",
      "Epoch 3/10\n",
      "19/19 [==============================] - 0s 959us/step - loss: 549.4327\n",
      "Epoch 4/10\n",
      "19/19 [==============================] - 0s 955us/step - loss: 441.2880\n",
      "Epoch 5/10\n",
      "19/19 [==============================] - 0s 887us/step - loss: 373.1752\n",
      "Epoch 6/10\n",
      "19/19 [==============================] - 0s 889us/step - loss: 298.3076\n",
      "Epoch 7/10\n",
      "19/19 [==============================] - 0s 843us/step - loss: 172.3108\n",
      "Epoch 8/10\n",
      "19/19 [==============================] - 0s 775us/step - loss: 93.5983\n",
      "Epoch 9/10\n",
      "19/19 [==============================] - 0s 794us/step - loss: 91.6103\n",
      "Epoch 10/10\n",
      "19/19 [==============================] - 0s 830us/step - loss: 91.1878\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 79.4919\n",
      "The MSE value is:  79.49186706542969\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(10, activation='relu', input_shape=(n_features,)))\n",
    "model.add(Dense(8, activation='relu'))\n",
    "model.add(Dense(1))\n",
    "\n",
    "optimizer = RMSprop(0.1) # 0.1 is the learning rate\n",
    "model.compile(loss='mean_squared_error',optimizer=optimizer) # compile the model\n",
    "\n",
    "# fit the model\n",
    "model.fit(X_train, y_train, epochs=10, batch_size=15, verbose = 1)\n",
    "\n",
    "# evaluate the model\n",
    "print('The MSE value is: ', model.evaluate(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "57/57 [==============================] - 0s 884us/step - loss: 412.7021\n",
      "Epoch 2/10\n",
      "57/57 [==============================] - 0s 779us/step - loss: 194.7878\n",
      "Epoch 3/10\n",
      "57/57 [==============================] - 0s 732us/step - loss: 162.8362\n",
      "Epoch 4/10\n",
      "57/57 [==============================] - 0s 667us/step - loss: 162.7744\n",
      "Epoch 5/10\n",
      "57/57 [==============================] - 0s 647us/step - loss: 138.7641\n",
      "Epoch 6/10\n",
      "57/57 [==============================] - 0s 658us/step - loss: 131.0418\n",
      "Epoch 7/10\n",
      "57/57 [==============================] - 0s 661us/step - loss: 97.9834\n",
      "Epoch 8/10\n",
      "57/57 [==============================] - 0s 608us/step - loss: 96.0629\n",
      "Epoch 9/10\n",
      "57/57 [==============================] - 0s 663us/step - loss: 90.2313\n",
      "Epoch 10/10\n",
      "57/57 [==============================] - 0s 656us/step - loss: 93.4776\n",
      "4/4 [==============================] - 0s 997us/step - loss: 79.2611\n",
      "The MSE value is:  79.26112365722656\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(10, activation='relu', input_shape=(n_features,)))\n",
    "model.add(Dense(8, activation='relu'))\n",
    "model.add(Dense(1))\n",
    "\n",
    "optimizer = RMSprop(0.1) # 0.1 is the learning rate\n",
    "model.compile(loss='mean_squared_error',optimizer=optimizer) # compile the model\n",
    "\n",
    "# fit the model\n",
    "model.fit(X_train, y_train, epochs=10, batch_size=5, verbose = 1)\n",
    "\n",
    "# evaluate the model\n",
    "print('The MSE value is: ', model.evaluate(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 3113.3433\n",
      "Epoch 2/10\n",
      "29/29 [==============================] - 0s 797us/step - loss: 484.6188\n",
      "Epoch 3/10\n",
      "29/29 [==============================] - 0s 679us/step - loss: 387.8465\n",
      "Epoch 4/10\n",
      "29/29 [==============================] - 0s 768us/step - loss: 303.1146\n",
      "Epoch 5/10\n",
      "29/29 [==============================] - 0s 715us/step - loss: 232.1322\n",
      "Epoch 6/10\n",
      "29/29 [==============================] - 0s 687us/step - loss: 176.3444\n",
      "Epoch 7/10\n",
      "29/29 [==============================] - 0s 801us/step - loss: 137.4416\n",
      "Epoch 8/10\n",
      "29/29 [==============================] - 0s 811us/step - loss: 111.4704\n",
      "Epoch 9/10\n",
      "29/29 [==============================] - 0s 725us/step - loss: 97.0912\n",
      "Epoch 10/10\n",
      "29/29 [==============================] - 0s 668us/step - loss: 92.4708\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 79.0813\n",
      "The MSE value is:  79.08125305175781\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(10, activation='relu', input_shape=(n_features,)))\n",
    "model.add(Dense(8, activation='relu'))\n",
    "model.add(Dense(1))\n",
    "\n",
    "optimizer = RMSprop(0.1) # 0.1 is the learning rate\n",
    "model.compile(loss='mean_squared_error',optimizer=optimizer) # compile the model\n",
    "\n",
    "# fit the model\n",
    "model.fit(X_train, y_train, epochs=10, batch_size=10, verbose = 1)\n",
    "\n",
    "# evaluate the model\n",
    "print('The MSE value is: ', model.evaluate(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 9273.4424\n",
      "Epoch 2/10\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 269.5329\n",
      "Epoch 3/10\n",
      "26/26 [==============================] - 0s 828us/step - loss: 193.2855\n",
      "Epoch 4/10\n",
      "26/26 [==============================] - 0s 846us/step - loss: 181.3482\n",
      "Epoch 5/10\n",
      "26/26 [==============================] - 0s 771us/step - loss: 164.7063\n",
      "Epoch 6/10\n",
      "26/26 [==============================] - 0s 727us/step - loss: 146.8150\n",
      "Epoch 7/10\n",
      "26/26 [==============================] - 0s 723us/step - loss: 94.8408\n",
      "Epoch 8/10\n",
      "26/26 [==============================] - 0s 758us/step - loss: 92.0420\n",
      "Epoch 9/10\n",
      "26/26 [==============================] - 0s 741us/step - loss: 91.1540\n",
      "Epoch 10/10\n",
      "26/26 [==============================] - 0s 799us/step - loss: 92.6890\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 82.2771\n",
      "The MSE value is:  82.27708435058594\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(10, activation='relu', input_shape=(n_features,)))\n",
    "model.add(Dense(8, activation='relu'))\n",
    "model.add(Dense(1))\n",
    "\n",
    "optimizer = RMSprop(0.1) # 0.1 is the learning rate\n",
    "model.compile(loss='mean_squared_error',optimizer=optimizer) # compile the model\n",
    "\n",
    "# fit the model\n",
    "model.fit(X_train, y_train, epochs=10, batch_size=11, verbose = 1)\n",
    "\n",
    "# evaluate the model\n",
    "print('The MSE value is: ', model.evaluate(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "implementing the huyperparameters using the GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Cannot clone object '<tensorflow.python.keras.engine.sequential.Sequential object at 0x0000023E902C0820>' (type <class 'tensorflow.python.keras.engine.sequential.Sequential'>): it does not seem to be a scikit-learn estimator as it does not implement a 'get_params' method.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-141-2941936c4fd8>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[0mparam_grid\u001b[0m \u001b[1;33m=\u001b[0m\u001b[0mdict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_size\u001b[0m \u001b[1;33m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mepochs\u001b[0m \u001b[1;33m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[0mgrid\u001b[0m \u001b[1;33m=\u001b[0m\u001b[0mGridSearchCV\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mestimator\u001b[0m \u001b[1;33m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mparam_grid\u001b[0m \u001b[1;33m=\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mscoring\u001b[0m \u001b[1;33m=\u001b[0m\u001b[1;34m'neg_mean_squared_error'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mn_jobs\u001b[0m \u001b[1;33m=\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m \u001b[0mgrid_result\u001b[0m  \u001b[1;33m=\u001b[0m\u001b[0mgrid\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     15\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Best %f using %s\"\u001b[0m \u001b[1;33m%\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgrid_result\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbest_score_\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mgrid_result\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbest_params_\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 63\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     64\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m             \u001b[1;31m# extra_args > 0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[0;32m    763\u001b[0m         \u001b[0mn_splits\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv_orig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_n_splits\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgroups\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    764\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 765\u001b[1;33m         \u001b[0mbase_estimator\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclone\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mestimator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    766\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    767\u001b[0m         parallel = Parallel(n_jobs=self.n_jobs,\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 63\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     64\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m             \u001b[1;31m# extra_args > 0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\base.py\u001b[0m in \u001b[0;36mclone\u001b[1;34m(estimator, safe)\u001b[0m\n\u001b[0;32m     65\u001b[0m                                 \"scikit-learn estimator instead of a class.\")\n\u001b[0;32m     66\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 67\u001b[1;33m                 raise TypeError(\"Cannot clone object '%s' (type %s): \"\n\u001b[0m\u001b[0;32m     68\u001b[0m                                 \u001b[1;34m\"it does not seem to be a scikit-learn \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     69\u001b[0m                                 \u001b[1;34m\"estimator as it does not implement a \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: Cannot clone object '<tensorflow.python.keras.engine.sequential.Sequential object at 0x0000023E902C0820>' (type <class 'tensorflow.python.keras.engine.sequential.Sequential'>): it does not seem to be a scikit-learn estimator as it does not implement a 'get_params' method."
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "model =Sequential()\n",
    "model.add(Dense(10, activation ='relu',input_shape=(n_features,)))\n",
    "model.add(Dense(8,activation ='relu'))\n",
    "model.add(Dense(1))\n",
    "optimizer =RMSprop(0.1)\n",
    "model.compile(optimizer =optimizer,loss ='mean_squared_error')\n",
    "\n",
    "\n",
    "batch_size =[10,20,30,40,50,60,70,80,90,100]\n",
    "epochs =[10,50,75,100]\n",
    "param_grid =dict(batch_size =batch_size,epochs =epochs)\n",
    "grid =GridSearchCV(estimator =model,param_grid =param_grid,scoring ='neg_mean_squared_error',n_jobs =-1)\n",
    "grid_result  =grid.fit(X_train,y_train)\n",
    "print(\"Best %f using %s\" %(grid_result.best_score_,grid_result.best_params_))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/75\n",
      "15/15 [==============================] - 1s 2ms/step - loss: 702.2307 - mse: 702.2307\n",
      "Epoch 2/75\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 87.7585 - mse: 87.7585\n",
      "Epoch 3/75\n",
      "15/15 [==============================] - 0s 608us/step - loss: 93.4895 - mse: 93.4895\n",
      "Epoch 4/75\n",
      "15/15 [==============================] - 0s 544us/step - loss: 93.1027 - mse: 93.1027\n",
      "Epoch 5/75\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 80.8716 - mse: 80.8716\n",
      "Epoch 6/75\n",
      "15/15 [==============================] - 0s 584us/step - loss: 74.5617 - mse: 74.5617\n",
      "Epoch 7/75\n",
      "15/15 [==============================] - 0s 436us/step - loss: 79.5768 - mse: 79.5768\n",
      "Epoch 8/75\n",
      "15/15 [==============================] - 0s 910us/step - loss: 73.0100 - mse: 73.0100\n",
      "Epoch 9/75\n",
      "15/15 [==============================] - 0s 469us/step - loss: 74.0922 - mse: 74.0922\n",
      "Epoch 10/75\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 68.1529 - mse: 68.1529\n",
      "Epoch 11/75\n",
      "15/15 [==============================] - 0s 477us/step - loss: 65.7015 - mse: 65.7015\n",
      "Epoch 12/75\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 70.7277 - mse: 70.7277\n",
      "Epoch 13/75\n",
      "15/15 [==============================] - 0s 886us/step - loss: 68.2088 - mse: 68.2088\n",
      "Epoch 14/75\n",
      "15/15 [==============================] - 0s 616us/step - loss: 57.8806 - mse: 57.8807\n",
      "Epoch 15/75\n",
      "15/15 [==============================] - 0s 548us/step - loss: 53.7832 - mse: 53.7832\n",
      "Epoch 16/75\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 62.5864 - mse: 62.5864\n",
      "Epoch 17/75\n",
      "15/15 [==============================] - 0s 712us/step - loss: 52.9210 - mse: 52.9210\n",
      "Epoch 18/75\n",
      "15/15 [==============================] - 0s 651us/step - loss: 57.3119 - mse: 57.3119\n",
      "Epoch 19/75\n",
      "15/15 [==============================] - 0s 928us/step - loss: 52.8921 - mse: 52.8921\n",
      "Epoch 20/75\n",
      "15/15 [==============================] - 0s 784us/step - loss: 54.6635 - mse: 54.6635\n",
      "Epoch 21/75\n",
      "15/15 [==============================] - 0s 646us/step - loss: 51.6667 - mse: 51.6667\n",
      "Epoch 22/75\n",
      "15/15 [==============================] - 0s 549us/step - loss: 51.7340 - mse: 51.7340\n",
      "Epoch 23/75\n",
      "15/15 [==============================] - 0s 619us/step - loss: 47.8228 - mse: 47.8228\n",
      "Epoch 24/75\n",
      "15/15 [==============================] - 0s 758us/step - loss: 49.2324 - mse: 49.2324\n",
      "Epoch 25/75\n",
      "15/15 [==============================] - 0s 899us/step - loss: 53.5949 - mse: 53.5949\n",
      "Epoch 26/75\n",
      "15/15 [==============================] - 0s 582us/step - loss: 40.0206 - mse: 40.0206\n",
      "Epoch 27/75\n",
      "15/15 [==============================] - 0s 1000us/step - loss: 52.6433 - mse: 52.6433\n",
      "Epoch 28/75\n",
      "15/15 [==============================] - 0s 583us/step - loss: 43.5430 - mse: 43.5430\n",
      "Epoch 29/75\n",
      "15/15 [==============================] - 0s 567us/step - loss: 42.9740 - mse: 42.9740\n",
      "Epoch 30/75\n",
      "15/15 [==============================] - 0s 761us/step - loss: 49.6900 - mse: 49.6900\n",
      "Epoch 31/75\n",
      "15/15 [==============================] - 0s 579us/step - loss: 43.3625 - mse: 43.3625\n",
      "Epoch 32/75\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 44.2344 - mse: 44.2344\n",
      "Epoch 33/75\n",
      "15/15 [==============================] - 0s 649us/step - loss: 43.6041 - mse: 43.6041\n",
      "Epoch 34/75\n",
      "15/15 [==============================] - 0s 604us/step - loss: 50.3571 - mse: 50.3571\n",
      "Epoch 35/75\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 37.3475 - mse: 37.3475\n",
      "Epoch 36/75\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 46.7217 - mse: 46.7217\n",
      "Epoch 37/75\n",
      "15/15 [==============================] - 0s 887us/step - loss: 35.5022 - mse: 35.5022\n",
      "Epoch 38/75\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 42.0919 - mse: 42.0919\n",
      "Epoch 39/75\n",
      "15/15 [==============================] - 0s 702us/step - loss: 37.3293 - mse: 37.3293\n",
      "Epoch 40/75\n",
      "15/15 [==============================] - 0s 856us/step - loss: 40.9926 - mse: 40.9926\n",
      "Epoch 41/75\n",
      "15/15 [==============================] - 0s 606us/step - loss: 35.5715 - mse: 35.5715\n",
      "Epoch 42/75\n",
      "15/15 [==============================] - 0s 917us/step - loss: 36.0662 - mse: 36.0662\n",
      "Epoch 43/75\n",
      "15/15 [==============================] - 0s 606us/step - loss: 38.7834 - mse: 38.7834\n",
      "Epoch 44/75\n",
      "15/15 [==============================] - 0s 987us/step - loss: 45.8261 - mse: 45.8261\n",
      "Epoch 45/75\n",
      "15/15 [==============================] - 0s 848us/step - loss: 29.4899 - mse: 29.4899\n",
      "Epoch 46/75\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 34.3640 - mse: 34.3640\n",
      "Epoch 47/75\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 37.6717 - mse: 37.6717\n",
      "Epoch 48/75\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 39.3406 - mse: 39.3406\n",
      "Epoch 49/75\n",
      "15/15 [==============================] - 0s 763us/step - loss: 38.1460 - mse: 38.1460\n",
      "Epoch 50/75\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 32.9940 - mse: 32.9940\n",
      "Epoch 51/75\n",
      "15/15 [==============================] - 0s 843us/step - loss: 47.2939 - mse: 47.2939\n",
      "Epoch 52/75\n",
      "15/15 [==============================] - 0s 681us/step - loss: 34.3908 - mse: 34.3908\n",
      "Epoch 53/75\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 33.7847 - mse: 33.7847\n",
      "Epoch 54/75\n",
      "15/15 [==============================] - 0s 622us/step - loss: 36.6618 - mse: 36.6618\n",
      "Epoch 55/75\n",
      "15/15 [==============================] - 0s 351us/step - loss: 33.3778 - mse: 33.3778\n",
      "Epoch 56/75\n",
      "15/15 [==============================] - 0s 679us/step - loss: 32.9158 - mse: 32.9158\n",
      "Epoch 57/75\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 43.5556 - mse: 43.5556\n",
      "Epoch 58/75\n",
      "15/15 [==============================] - 0s 276us/step - loss: 28.0707 - mse: 28.0707\n",
      "Epoch 59/75\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 33.9780 - mse: 33.9780\n",
      "Epoch 60/75\n",
      "15/15 [==============================] - 0s 820us/step - loss: 31.7084 - mse: 31.7084\n",
      "Epoch 61/75\n",
      "15/15 [==============================] - 0s 943us/step - loss: 37.4618 - mse: 37.4618\n",
      "Epoch 62/75\n",
      "15/15 [==============================] - 0s 821us/step - loss: 29.1699 - mse: 29.1699\n",
      "Epoch 63/75\n",
      "15/15 [==============================] - 0s 840us/step - loss: 51.8552 - mse: 51.8552\n",
      "Epoch 64/75\n",
      "15/15 [==============================] - 0s 945us/step - loss: 28.5326 - mse: 28.5326\n",
      "Epoch 65/75\n",
      "15/15 [==============================] - 0s 743us/step - loss: 35.0132 - mse: 35.0132\n",
      "Epoch 66/75\n",
      "15/15 [==============================] - 0s 997us/step - loss: 42.5378 - mse: 42.5378\n",
      "Epoch 67/75\n",
      "15/15 [==============================] - 0s 881us/step - loss: 36.3906 - mse: 36.3906\n",
      "Epoch 68/75\n",
      "15/15 [==============================] - 0s 334us/step - loss: 33.1516 - mse: 33.1516\n",
      "Epoch 69/75\n",
      "15/15 [==============================] - 0s 366us/step - loss: 31.7644 - mse: 31.7644\n",
      "Epoch 70/75\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 37.0229 - mse: 37.0229\n",
      "Epoch 71/75\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 29.7228 - mse: 29.7228\n",
      "Epoch 72/75\n",
      "15/15 [==============================] - 0s 579us/step - loss: 38.3102 - mse: 38.3102\n",
      "Epoch 73/75\n",
      "15/15 [==============================] - 0s 376us/step - loss: 30.0396 - mse: 30.0396\n",
      "Epoch 74/75\n",
      "15/15 [==============================] - 0s 866us/step - loss: 28.2159 - mse: 28.2159\n",
      "Epoch 75/75\n",
      "15/15 [==============================] - 0s 399us/step - loss: 30.9410 - mse: 30.9410\n",
      "Best -37.898496 using {'batch_size': 20, 'epochs': 75}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from keras.wrappers.scikit_learn import KerasRegressor\n",
    "#defining the model\n",
    "def create_model(optimizer=RMSprop(0.01)):\n",
    "    model =Sequential()\n",
    "    model.add(Dense(10, activation ='relu',input_shape=(n_features,)))\n",
    "    model.add(Dense(8,activation ='relu'))\n",
    "    model.add(Dense(1))\n",
    "    #optimizer =RMSprop(0.1)\n",
    "    model.compile(optimizer =optimizer,loss ='mean_squared_error',metrics =['mse'])\n",
    "    return model\n",
    "model =KerasRegressor(build_fn=create_model, verbose=1)\n",
    "\n",
    "#defining the hyperparameters for grid to be validated\n",
    "batch_size =[10,20,30,40,50,60,70,80,90,100]\n",
    "epochs =[10,50,75,100]\n",
    "param_grid =dict(batch_size =batch_size,epochs =epochs)\n",
    "grid =GridSearchCV(estimator =model,param_grid =param_grid,scoring ='neg_mean_squared_error',n_jobs =-1)\n",
    "# run the GridSearchCV process\n",
    "grid_result  =grid.fit(X_train,y_train)\n",
    "#print the results\n",
    "print(\"Best %f using %s\" %(grid_result.best_score_,grid_result.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
